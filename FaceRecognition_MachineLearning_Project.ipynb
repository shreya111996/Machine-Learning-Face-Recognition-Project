{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing necessary Libraries**"
      ],
      "metadata": {
        "id": "Fls_MOZc-aud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u49-vWDgYc24"
      },
      "outputs": [],
      "source": [
        "!pip install pyheif\n",
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary Libraries/ Modules**"
      ],
      "metadata": {
        "id": "x6IwvVfO-Pt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyheif\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from deepface import DeepFace\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "M3uaZRlsZQvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Mounting the Google drive\n",
        "\"\"\"\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TFNcM1Y7KY-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Declaring constant variables for file paths\n",
        "'''\n",
        "# TRAINING_DATA_DIRECTORY = \"/content/drive/MyDrive/Project/training\"\n",
        "# TRAINING_DATA_RENAMED_DIRECTORY = \"/content/drive/My Drive/Project/Release_Renamed/\"\n",
        "# TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY = \"/content/drive/My Drive/Project/Release_with_flip/\"\n",
        "# TESTING_DATA_DIRECTORY = \"/content/drive/My Drive/Project/test/\""
      ],
      "metadata": {
        "id": "a0RJJRT4DOHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleanup and augmentation functions for Training dataset**"
      ],
      "metadata": {
        "id": "_qSJD47bUNsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This method should be only run once on the initial raw training set.\n",
        "This function renames all files to a standard serialized format (<filename>_IMG.jpg).\n",
        "\"\"\"\n",
        "def rename_image_files():\n",
        "  if os.path.isdir(TRAINING_DATA_RENAMED_DIRECTORY)==False:\n",
        "    os.mkdir(TRAINING_DATA_RENAMED_DIRECTORY)\n",
        "  for i, dirname in enumerate(os.listdir(TRAINING_DATA_DIRECTORY)):\n",
        "    directory = TRAINING_DATA_DIRECTORY+dirname\n",
        "    for j, fname in enumerate(os.listdir(directory)):\n",
        "      newname = dirname+\"_IMG\"+str(j+1)+\".jpg\"\n",
        "      if fname.endswith('HEIC'):\n",
        "        print(directory+\"/\"+fname)\n",
        "        heif_file = pyheif.read(directory+\"/\"+fname)\n",
        "        image = Image.frombytes(heif_file.mode, heif_file.size, heif_file.data)\n",
        "        image.save(TRAINING_DATA_RENAMED_DIRECTORY+newname)\n",
        "      else:\n",
        "        image = cv.imread(directory+\"/\"+fname)\n",
        "        cv.imwrite(TRAINING_DATA_RENAMED_DIRECTORY+newname, image)"
      ],
      "metadata": {
        "id": "lSqro3A6UYBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This method parses all the training image files and performs augmentation on the dataset.\n",
        "It uses the DeepFace.extract_faces function to extract faces from images.\n",
        "The extracted face is then processed to remove black margins added by default by DeepFace, and its size is adjusted using OpenCV\n",
        "This generates new images with applied augmentations.\n",
        "\"\"\"\n",
        "def extract_training_data_and_augment(TRAINING_DATA_RENAMED_DIRECTORY):\n",
        "  start_time = datetime.now()\n",
        "  if os.path.isdir(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY)==False:\n",
        "    os.mkdir(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY)\n",
        "  os.chdir(TRAINING_DATA_RENAMED_DIRECTORY)\n",
        "  for fname in os.listdir(TRAINING_DATA_RENAMED_DIRECTORY):\n",
        "    print(str(fname))\n",
        "    img = DeepFace.extract_faces(fname, target_size=(110,110), detector_backend = \"mtcnn\", grayscale=True)\n",
        "    img_data = img[0]['face']\n",
        "    img_data = img_data[:,11:99]  #Removing the black margin added by default by DeepFace\n",
        "    img_data = cv.resize(img_data,(88,88))\n",
        "    cv.imwrite(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY+fname[:fname.index('.')]+\"_1.jpg\", img_data * 255)\n",
        "\n",
        "    #Data Augmentation code:\n",
        "\n",
        "    #Mirroring the extracted face\n",
        "    flipped_img=cv.flip(img_data,1)\n",
        "    cv.imwrite(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY+fname[:fname.index('.')]+\"_2.jpg\", flipped_img * 255)\n",
        "\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return execution_time"
      ],
      "metadata": {
        "id": "SAdzZsuFV3ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Other data augmentations explored\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "      alpha = 1.5\n",
        "      beta = 10\n",
        "\n",
        "      #Image Rotation\n",
        "      rotated_image_1=ndimage.rotate(img_data,10,reshape=False) #Rotating the extracted face by 10 degrees to the right\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_3.jpg\", rotated_image_1*255)\n",
        "\n",
        "      rotated_image_2=ndimage.rotate(img_data,-10,reshape=False) #Rotating the extracted face by 10 degrees to the left\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_4.jpg\", rotated_image_2*255)\n",
        "\n",
        "      #Sharpening images\n",
        "      #sharpened_img=cv.filter2D(img[0]['face'], -1, kernel)\n",
        "\n",
        "      #Brightness and contrast control\n",
        "      img_gamma_1=np.power(img_data*255, 1.1).clip(0,255).astype(np.uint8) #Gamma Changes to images - making it brighter #Clip used to keep the value between 0 and 255\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_5.jpg\", img_gamma_1)\n",
        "\n",
        "      img_gamma_2=np.power(img_data*255, 0.9).clip(0,255).astype(np.uint8) #Gamma Changes to images - making it darker\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_6.jpg\", img_gamma_2)\n",
        "\n",
        "      img_gamma_1 = cv.convertScaleAbs(img_data*255, alpha=alpha, beta=beta)       #Gamma changes\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_5.jpg\", img_gamma_1)\n",
        "\n",
        "      #Stretch along x-axis\n",
        "      h, w = img_data.shape[:2]\n",
        "      elongated_image = cv.resize(img_data, None, fx=1.05, fy=1)\n",
        "      trim_left = ((elongated_image.shape[1]-w)//2)\n",
        "      cv.imwrite(augmented_data_directory+fname[:fname.index('.')]+\"_3.jpg\", elongated_image[0:h, trim_left:trim_left+w] * 255)\n",
        "\n",
        "      #Zooming images\n",
        "      h, w = img_data.shape[:2]\n",
        "      zoom_factor=1.1\n",
        "      zh = int(np.round(h / zoom_factor))\n",
        "      zw = int(np.round(w / zoom_factor))\n",
        "      top = (h - zh) // 2\n",
        "      left = (w - zw) // 2\n",
        "\n",
        "      out = zoom(img_data[top:top+zh, left:left+zw], zoom_factor)\n",
        "\n",
        "      # `out` might still be slightly larger than `img` due to rounding, so\n",
        "      # trim off any extra pixels at the edges\n",
        "      trim_top = ((out.shape[0] - h) // 2)\n",
        "      trim_left = ((out.shape[1] - w) // 2)\n",
        "      out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "      cv.imwrite(curated_data_directory+fname[:fname.index('.')]+\"_3.jpg\", out * 255)\n",
        "      \"\"\""
      ],
      "metadata": {
        "id": "SR-vwKWjQccL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function call to extract training data and perform augmentation on it. CAN BE SKIPPED.**"
      ],
      "metadata": {
        "id": "CGLxDFEbZry-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rename_image_files()\n",
        "total_execution_time = extract_training_data_and_augment(TRAINING_DATA_RENAMED_DIRECTORY)\n",
        "print('Time required for extracting faces from files and performing augmentation: ', total_execution_time )"
      ],
      "metadata": {
        "id": "51XRIwatYUg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Necessary functions**"
      ],
      "metadata": {
        "id": "s5ncdoXqTaB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function takes a list of arrays, assume they have the same shape (based on the shape of the first array), and\n",
        "returns a new 2D NumPy array where each original array is flattened.\n",
        "\"\"\"\n",
        "def flatten_data(data):\n",
        "  original_shape = data[0].shape\n",
        "  data_flattened = np.array([data[i].flatten() for i in range(len(data))])\n",
        "  return data_flattened"
      ],
      "metadata": {
        "id": "jP-oTe4ZAg8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function reads and preprocess training data for a machine learning model.\n",
        "This code assumes that the images are grayscale and that the class names are present in the file names before the first underscore.\n",
        "Additionally, it uses OpenCV (cv) for image reading and manipulation.\n",
        "Returns training data and corresponding labels.\n",
        "\"\"\"\n",
        "def read_training_data():\n",
        "  data = []\n",
        "  labels = []\n",
        "  os.chdir(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY)\n",
        "  for fname in os.listdir(TRAINING_DATA_WITH_AUGMENTATION_DIRECTORY):\n",
        "    data.append(cv.imread(fname,cv.IMREAD_GRAYSCALE)/255)\n",
        "    classname = fname[:fname.index('_')]\n",
        "    labels.append(classname)\n",
        "  y_train = np.array(labels)\n",
        "  x_train = flatten_data(data)\n",
        "  return x_train, y_train"
      ],
      "metadata": {
        "id": "oy8WhQHeZkbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"This function reads and preprocess testing data for a machine learning model.\n",
        "This code performs following action:\n",
        "  1. Reads the testing dataset from the specific folder\n",
        "  2. Extracts the labels from the .txt file\n",
        "  3. Crops faces using DeepFace\n",
        "  4. Resizes the image to a certain size\n",
        "Returns testing data and labels.\n",
        "\"\"\"\n",
        "\n",
        "def read_testing_data():\n",
        "  start_time = datetime.now()\n",
        "  os.chdir(TESTING_DATA_DIRECTORY)\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  test_labels = {}\n",
        "  label_file = open(\"labels.txt\",\"r\")\n",
        "\n",
        "  for l in label_file:\n",
        "    key = l.split()[0].strip()\n",
        "    value = l.split()[1].strip()\n",
        "    test_labels[key] = value\n",
        "\n",
        "  for fname in os.listdir(TESTING_DATA_DIRECTORY):\n",
        "    if '.jpg' in fname.lower() or '.png' in fname.lower() or '.jpeg' in fname.lower():\n",
        "      print(fname)\n",
        "      img = DeepFace.extract_faces(fname, target_size = (110,110), detector_backend = \"mtcnn\", grayscale = True)\n",
        "      img_data = img[0]['face']\n",
        "      img_data = img_data[:,11:99]\n",
        "      img_data = cv.resize(img_data,(88,88))\n",
        "      x_test.append(img_data)\n",
        "      y_test.append(test_labels[fname])\n",
        "\n",
        "  y_test = np.array(y_test)\n",
        "  x_test = flatten_data(x_test)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return x_test, y_test, execution_time"
      ],
      "metadata": {
        "id": "J2RywT-WAy0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code implements Linear Discriminant Analysis (LDA) for classification.\n",
        "Calculates and returns the accuracy score by comparing the predicted labels (y_pred) with the true labels (y_test).\n",
        "\"\"\"\n",
        "def lda(x_train, y_train, x_test, y_test):\n",
        "  start_time = datetime.now()\n",
        "  lda = LinearDiscriminantAnalysis()\n",
        "  lda.fit(x_train, y_train)\n",
        "  y_pred = lda.predict(x_test)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return accuracy_score(y_test, y_pred), execution_time"
      ],
      "metadata": {
        "id": "-5Ts3obHGnow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code performs dimensionality reduction using LDA with a specified number of components (no_components).\n",
        "Returns the trained LDA model.\n",
        "\"\"\"\n",
        "def lda_dimension_reduction(x_train, y_train, no_of_components):\n",
        "  lda_data = LinearDiscriminantAnalysis(n_components = no_of_components)\n",
        "  lda_data.fit(x_train, y_train)\n",
        "  return lda_data"
      ],
      "metadata": {
        "id": "4rKYKBOOKImN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code is designed to transform data to a reduced dimensionality using a pre-trained LDA model.\n",
        "\"\"\"\n",
        "def transformation_to_reduced_dimension(lda, data):\n",
        "  return lda.transform(data)"
      ],
      "metadata": {
        "id": "Vp7eKJUtLo2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code implements the k-Nearest Neighbors (kNN) algorithm for classification.\n",
        "Calculates and returns the accuracy score by comparing the predicted labels (y_pred) with the true labels (y_test).\n",
        "\"\"\"\n",
        "def knn(x_train, y_train, x_test, y_test):\n",
        "  start_time = datetime.now()\n",
        "  knn_clf = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
        "  knn_clf.fit(x_train, y_train)\n",
        "  y_pred = knn_clf.predict(x_test)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return accuracy_score(y_test, y_pred), execution_time"
      ],
      "metadata": {
        "id": "-c-n3G2AK0wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code implements a One-Vs-Rest Support Vector Machine (SVM) classifier with cross-validation.\n",
        "Returns the average accuracy over the 10 iterations, effectively performing a form of 10-fold cross-validation.\n",
        "\"\"\"\n",
        "def svm_one_vs_rest(x_train, y_train, x_test, y_test, c):\n",
        "  start_time = datetime.now()\n",
        "  accuracy = 0\n",
        "  for i in range(10):\n",
        "    svc = SVC(C = c, probability = True)\n",
        "    ovr_clf = OneVsRestClassifier(svc)\n",
        "    ovr_clf = ovr_clf.fit(x_train, y_train)\n",
        "    y_pred = ovr_clf.predict(x_test)\n",
        "    accuracy += accuracy_score(y_test, y_pred)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return (accuracy/10), execution_time"
      ],
      "metadata": {
        "id": "snNxFS0UM94Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_one_vs_rest_with_gamma(x_train, y_train, x_test, y_test, gamma, degree):\n",
        "  start_time = datetime.now()\n",
        "  svc_gamma = SVC (gamma = gamma, degree = degree)\n",
        "  ovr_gamma = OneVsRestClassifier(svc_gamma)\n",
        "  ovr_gamma = ovr_gamma.fit(x_reduced_train,y_train)\n",
        "  y_pred = ovr_gamma.predict(x_reduced_test)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return accuracy_score(y_test,y_pred), execution_time"
      ],
      "metadata": {
        "id": "PqloW5TOVn6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This code implements an ensemble model using Stacking.\n",
        "Defines a list of base estimators, k-Nearest Neighbors classifier, a one-vs-rest Support Vector Classifier and a Linear Discriminant Analysis classifier and\n",
        "logistic regression classifier as the final estimator.\n",
        "Calculates and returns the accuracy score by comparing the predicted labels (y_pred) with the true labels (y_test).\n",
        "\"\"\"\n",
        "def ensemble_model(x_train, y_train, x_test, y_test):\n",
        "  start_time = datetime.now()\n",
        "  estimators = [('knn', KNeighborsClassifier(n_neighbors = 5, weights = 'distance')),\n",
        "                ('ovr_svc',OneVsRestClassifier(SVC(gamma = 0.001, degree = 1))),\n",
        "                ('lda',LinearDiscriminantAnalysis())]\n",
        "  ensemble_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "  ensemble_clf = ensemble_clf.fit(x_train, y_train)\n",
        "  y_pred = ensemble_clf.predict(x_test)\n",
        "  execution_time = datetime.now() - start_time\n",
        "  return accuracy_score(y_test, y_pred), execution_time"
      ],
      "metadata": {
        "id": "5dTedfWKPh3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function calls to train model and predict accuracy of models on testing data**"
      ],
      "metadata": {
        "id": "n5o_5tCuTkO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading training data\n",
        "x_train, y_train = read_training_data()\n",
        "print(\"Total images in training data: {}\".format(len(x_train)))\n",
        "print(\"Total number of classes: {}\".format(len(set(y_train))))\n",
        "\n",
        "#Reading testing data\n",
        "x_test, y_test, execution_time = read_testing_data()\n",
        "print(\"Total images in testing data: {}\".format(len(x_test)), 'Executed in: ', execution_time)\n",
        "\n",
        "#Calling function to claculate accuracy of LDA\n",
        "lda_accuracy, execution_time = lda(x_train, y_train, x_test, y_test)\n",
        "print(\"Accuracy using LDA model: {}\".format(lda_accuracy), ' Executed in: ', execution_time)\n",
        "\n",
        "#Calling function to perform dimension reduction using LDA with 32 number of components\n",
        "lda_data = lda_dimension_reduction(x_train, y_train, 32)\n",
        "x_reduced_train = transformation_to_reduced_dimension(lda_data, x_train)\n",
        "x_reduced_test = transformation_to_reduced_dimension(lda_data, x_test)\n",
        "\n",
        "#Calling function to calculate the accuracy of a kNN algorithm on reduced-dimensional data\n",
        "knn_accuracy, execution_time = knn(x_reduced_train, y_train, x_reduced_test, y_test)\n",
        "print(\"Accuracy using kNN classifier: {}\".format(knn_accuracy), ' Executed in: ', execution_time)\n",
        "\n",
        "#Calling function to calculate the accuracy of a SVM algorithm on reduced-dimensional data\n",
        "C = [1,2]\n",
        "for c in C:\n",
        "  svm_accuracy, execution_time = svm_one_vs_rest(x_reduced_train, y_train, x_reduced_test, y_test, c)\n",
        "  print(\"Accuracy using SVM One_Vs_Rest classifier c={}: {}\".format(c, svm_accuracy), ' Executed in: ', execution_time)\n",
        "\n",
        "svm_accuracy, execution_time = svm_one_vs_rest_with_gamma(x_reduced_train, y_train, x_reduced_test, y_test, 0.001, 1)\n",
        "print(\"Accuracy using SVM One_Vs_Rest classifier gamma={} and degree={}: {}\".format(0.001, 1, svm_accuracy), ' Executed in: ', execution_time)\n",
        "\n",
        "#Calling function to calculate the accuracy of a Stacking Classifier (kNN, SVM and LDA) on reduced-dimensional data\n",
        "ensemble_accuracy, execution_time = ensemble_model(x_reduced_train, y_train, x_reduced_test, y_test)\n",
        "print(\"Accuracy using Ensemble model: {}\".format(ensemble_accuracy), ' Executed in: ', execution_time)"
      ],
      "metadata": {
        "id": "K1yrVrVD1sdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sjIP7vJowevl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below are snippets of codes of other algorithms exploited**"
      ],
      "metadata": {
        "id": "5-HgPkqdY7N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_clf = RandomForestClassifier(n_estimators = 150, criterion = 'gini', max_depth = 13)\n",
        "rfc_clf = rfc_clf.fit(x_reduced_train, y_train)\n",
        "y_pred = rfc_clf.predict(x_reduced_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy using random forest algorithm: {}\".format(rf_accuracy))"
      ],
      "metadata": {
        "id": "E_K1YbG7SWUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "C = [1,2,3,4,5,8,16,32]\n",
        "for c in C:\n",
        "  acc = 0\n",
        "  for i in range(10):\n",
        "    svc = SVC (C = c, probability = True)\n",
        "    ovo = OneVsOneClassifier(svc)\n",
        "    ovo = ovo.fit(x_reduced_train,y_train)\n",
        "    y_pred = ovo.predict(x_reduced_test)\n",
        "    acc += accuracy_score(y_test,y_pred)\n",
        "  print(\"Average accuracy for C={} is: {}\".format(c,acc/10))"
      ],
      "metadata": {
        "id": "ELKcY9Hv1DRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [('knn', KNeighborsClassifier(n_neighbors = 5, weights = 'distance')),\n",
        "                ('ovr_svc',OneVsRestClassifier(SVC (C = 1))),\n",
        "                ('lda',LinearDiscriminantAnalysis())]\n",
        "ensemble_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "ensemble_clf = ensemble_clf.fit(x_reduced_train, y_train)\n",
        "y_pred = ensemble_clf.predict(x_reduced_test)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "zRDcZUGC_aCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "C_range = np.logspace(-2, 10, 13)\n",
        "gamma_range = np.logspace(-9, 3, 13)\n",
        "kernel_range=('linear','rbf','poly')\n",
        "degree_range = (1,2,3,4,5,6,7,8,9,10)\n",
        "param_grid = dict(gamma=gamma_range, C=C_range, kernel=kernel_range,degree=degree_range)\n",
        "\n",
        "svm_grid = SVC()\n",
        "clf = GridSearchCV(svm_grid, param_grid)\n",
        "clf.fit(x_reduced_train,y_train)\n",
        "print(clf.best_estimator_)"
      ],
      "metadata": {
        "id": "j48zlOXkAzIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_best_fit = SVC(gamma=1e-09,kernel='linear',C=0.01)\n",
        "svc_best_fit = svc_best_fit.fit(x_reduced_train,y_train)\n",
        "y_pred = svc_best_fit.predict(x_reduced_test)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "7VWat-p7XN67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
        "clf = GaussianNB()\n",
        "clf = clf.fit(x_reduced_train,y_train)\n",
        "y_pred = clf.predict(x_reduced_test)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "es-KgcK-gw-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}